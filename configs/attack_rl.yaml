behaviors:
  RL_Attack:
    trainer_type: ppo

    hyperparameters:
      learning_rate: 3.0e-4
      batch_size:    1024
      buffer_size:   20480
      beta:          5.0e-4
      epsilon:       0.2
      lambd:         0.95
      num_epoch:     3

    network_settings:
      num_layers:   2
      hidden_units: 256
      normalize:    false

    reward_signals:
      extrinsic:
        gamma:     0.995
        strength:  1.0

    max_steps:      3000000
    time_horizon:   64
    summary_freq:   20000
